{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "### Submitted by Ankit Saini\n",
    "#### 17BT30002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Download the MNIST handwritten digit dataset. It contains 28X28 images. Flatten them into 784-dimensional binary vectors. Keep aside 20% data for testing and another 20% for validation. [1 mark]\n",
    "\n",
    "2) Now, draw a random subset of 10 dimensions (out of 784). Based on these 10 dimensions only, build a decision tree (using library function). Maximum depth allowed: 5. Calculate accuracy of the tree on validation set. [2 mark]\n",
    "\n",
    "3) Repeat this process for 50 random subsets like this, each of dimension 10.For each of them, build a decision tree of max. depth 5. Calculate accuracy on validation set. [2 marks]\n",
    "\n",
    "4) Carry out weighted classification of the test set using these 50 decision trees, along with their validation accuracies as weights. Report the accuracy. [1 marks]\n",
    "\n",
    "5) Starting with this ensemble as the initial classifier, implement Adaboost algorithm. At each stage, build a decision tree using entropy based on weighted examples as the heterogeneity measure of each node. Each tree will have maximum depth of 5. Maximum 20 iterations of Adaboost. [3 marks]\n",
    "\n",
    "6) Using this ensemble, carry out classification on the test set and report accuracy [1 mark]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import the requred libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Download the MNIST handwritten digit dataset. It contains 28X28 images. Flatten them into 784-dimensional binary vectors. Keep aside 20% data for testing and another 20% for validation. [1 mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"mnist_train.csv\"\n",
    "test_path = \"mnist_test.csv\"\n",
    "validate_path = \"mnist_validate.csv\"\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "validate_df = pd.read_csv(validate_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0          5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1          0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2          4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3          1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4          9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "41995      6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "41996      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "41997      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "41998      7    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "41999      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0          0      0      0      0      0      0      0      0  \n",
       "1          0      0      0      0      0      0      0      0  \n",
       "2          0      0      0      0      0      0      0      0  \n",
       "3          0      0      0      0      0      0      0      0  \n",
       "4          0      0      0      0      0      0      0      0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "41995      0      0      0      0      0      0      0      0  \n",
       "41996      0      0      0      0      0      0      0      0  \n",
       "41997      0      0      0      0      0      0      0      0  \n",
       "41998      0      0      0      0      0      0      0      0  \n",
       "41999      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['label']\n",
    "X = train_df[train_df.columns[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "discretize the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete(x):\n",
    "    x = x.T\n",
    "    \n",
    "    for i in x:\n",
    "        mean = np.mean(x[i])\n",
    "        a = []\n",
    "        for j in x[i]:\n",
    "            if j>mean:\n",
    "                a.append(1)\n",
    "            else:\n",
    "                a.append(0)\n",
    "        x[i] = a\n",
    "    return x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = discrete(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape (25200, 784)   | 60% split of total dataframe\n",
      "validation data shape (8400, 784)  | 20% split of total dataframe\n",
      "testing data shape (8400, 784)     | 20% split of total dataframe\n"
     ]
    }
   ],
   "source": [
    "print('training data shape',X_train.shape, '  | 60% split of total dataframe')\n",
    "print('validation data shape',X_val.shape, ' | 20% split of total dataframe')\n",
    "print('testing data shape',X_test.shape, '    | 20% split of total dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Now, draw a random subset of 10 dimensions (out of 784). Based on these 10 dimensions only, build a decision tree (using library function). Maximum depth allowed: 5. Calculate accuracy of the tree on validation set. [2 mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_random_subset = X_train[X_train.columns.to_series().sample(10)]\n",
    "X_val_random_subset = X_val[X_val.columns.to_series().sample(10)]\n",
    "X_test_random_subset = X_test[X_test.columns.to_series().sample(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 5, random_state = 42).fit(X_train_random_subset, y_train)\n",
    "y_val_pred = clf.predict(X_val_random_subset)\n",
    "y_test_pred = clf.predict(X_test_random_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy over validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17964285714285713\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_val,y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy over test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08535714285714285\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Repeat this process for 50 random subsets like this, each of dimension 10.For each of them, build a decision tree of max. depth 5. Calculate accuracy on validation set. [2 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation sample # 1\n",
      "0.0\n",
      "validation sample # 2\n",
      "0.2\n",
      "validation sample # 3\n",
      "0.2\n",
      "validation sample # 4\n",
      "0.1\n",
      "validation sample # 5\n",
      "0.2\n",
      "validation sample # 6\n",
      "0.2\n",
      "validation sample # 7\n",
      "0.2\n",
      "validation sample # 8\n",
      "0.3\n",
      "validation sample # 9\n",
      "0.1\n",
      "validation sample # 10\n",
      "0.0\n",
      "validation sample # 11\n",
      "0.2\n",
      "validation sample # 12\n",
      "0.2\n",
      "validation sample # 13\n",
      "0.1\n",
      "validation sample # 14\n",
      "0.0\n",
      "validation sample # 15\n",
      "0.3\n",
      "validation sample # 16\n",
      "0.0\n",
      "validation sample # 17\n",
      "0.1\n",
      "validation sample # 18\n",
      "0.1\n",
      "validation sample # 19\n",
      "0.1\n",
      "validation sample # 20\n",
      "0.2\n",
      "validation sample # 21\n",
      "0.1\n",
      "validation sample # 22\n",
      "0.2\n",
      "validation sample # 23\n",
      "0.4\n",
      "validation sample # 24\n",
      "0.2\n",
      "validation sample # 25\n",
      "0.2\n",
      "validation sample # 26\n",
      "0.4\n",
      "validation sample # 27\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARANSH\\Anaconda3\\envs\\saransh\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation sample # 28\n",
      "0.1\n",
      "validation sample # 29\n",
      "0.0\n",
      "validation sample # 30\n",
      "0.1\n",
      "validation sample # 31\n",
      "0.2\n",
      "validation sample # 32\n",
      "0.2\n",
      "validation sample # 33\n",
      "0.2\n",
      "validation sample # 34\n",
      "0.1\n",
      "validation sample # 35\n",
      "0.2\n",
      "validation sample # 36\n",
      "0.0\n",
      "validation sample # 37\n",
      "0.3\n",
      "validation sample # 38\n",
      "0.2\n",
      "validation sample # 39\n",
      "0.0\n",
      "validation sample # 40\n",
      "0.1\n",
      "validation sample # 41\n",
      "0.2\n",
      "validation sample # 42\n",
      "0.3\n",
      "validation sample # 43\n",
      "0.2\n",
      "validation sample # 44\n",
      "0.1\n",
      "validation sample # 45\n",
      "0.1\n",
      "validation sample # 46\n",
      "0.0\n",
      "validation sample # 47\n",
      "0.2\n",
      "validation sample # 48\n",
      "0.1\n",
      "validation sample # 49\n",
      "0.3\n",
      "validation sample # 50\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=50, random_state=42)\n",
    "\n",
    "trees = []\n",
    "\n",
    "for i in range(50):\n",
    "    j = random.randint(1,8000)\n",
    "    clf = DecisionTreeClassifier(max_depth = 5, random_state = 42).fit(X_train_random_subset[0:j+10], y_train[0:j+10])\n",
    "    trees.append(clf)\n",
    "    X_val_random_subset1 = X_val_random_subset[j:j+10]\n",
    "    y_val1 = y_val[j:j+10]\n",
    "    y_val_pred1 = clf.predict(X_val_random_subset1)\n",
    "    print('validation sample #',i+1)\n",
    "    print(accuracy_score(y_val1,y_val_pred1))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Carry out weighted classification of the test set using these 50 decision trees, along with their validation accuracies as weights. Report the accuracy. [1 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_classification(acc , y_val_pre):\n",
    "    \n",
    "    d = []\n",
    "    for i in range(50):\n",
    "        d.append(y_val_pre[i]*acc[i])\n",
    "        \n",
    "    b = []\n",
    "    for j in range(len(y_val_pre[0])):\n",
    "        for i in range(50):\n",
    "            a = 0\n",
    "            a+=d[i][j]\n",
    "        b.append(int(a))\n",
    "        \n",
    "        \n",
    "    return b  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "y_val_pre = []\n",
    "for w_classifier in trees:\n",
    "    yy = w_classifier.predict(X_val_random_subset)\n",
    "    y_val_pre.append(yy)\n",
    "    acc.append(accuracy_score(y_val,yy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy after weighted classification is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11916666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val,weighted_classification(acc , y_val_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Starting with this ensemble as the initial classifier, implement Adaboost algorithm. At each stage, build a decision tree using entropy based on weighted examples as the heterogeneity measure of each node. Each tree will have maximum depth of 5. Maximum 20 iterations of Adaboost. [3 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration # 1\n",
      "iteration # 2\n",
      "iteration # 3\n",
      "iteration # 4\n",
      "iteration # 5\n",
      "iteration # 6\n",
      "iteration # 7\n",
      "iteration # 8\n",
      "iteration # 9\n",
      "iteration # 10\n",
      "iteration # 11\n",
      "iteration # 12\n",
      "iteration # 13\n",
      "iteration # 14\n",
      "iteration # 15\n",
      "iteration # 16\n",
      "iteration # 17\n",
      "iteration # 18\n",
      "iteration # 19\n",
      "iteration # 20\n",
      "0.14547619047619048\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# HELPER FUNCTION: GET ERROR RATE\n",
    "def get_error_rate(pred, Y):\n",
    "    return sum(pred != Y) / float(len(Y))\n",
    "\n",
    "# HELPER FUNCTION: PRINT ERROR RATE\n",
    "def print_error_rate(err):\n",
    "    print ('Error rate: Training: %.4f - Test: %.4f' % err)\n",
    "\n",
    "# HELPER FUNCTION: GENERIC CLASSIFIER\n",
    "def generic_clf(y_train, X_train, y_test, X_test, clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    pred_train = clf.predict(X_train)\n",
    "    pred_test = clf.predict(X_test)\n",
    "    return get_error_rate(pred_train, y_train), \\\n",
    "           get_error_rate(pred_test, y_test)\n",
    "\n",
    "# ADABOOST IMPLEMENTATION\n",
    "def adaboost_clf(y_train, X_train, y_test, X_test, M, clf):\n",
    "    n_train, n_test = len(X_train), len(X_test)\n",
    "    # Initialize weights\n",
    "    w = np.ones(n_train) / n_train\n",
    "    pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
    "    \n",
    "    for i in range(20):\n",
    "        print('iteration #', i+1)\n",
    "        # Fit a classifier with the specific weights\n",
    "        clf.fit(X_train, y_train, sample_weight = w)\n",
    "        pred_train_i = clf.predict(X_train)\n",
    "        pred_test_i = clf.predict(X_test)\n",
    "        # Indicator function\n",
    "        miss = [int(x) for x in (pred_train_i != y_train)]\n",
    "        # Equivalent with 1/-1 to update weights\n",
    "        miss2 = [x if x==1 else -1 for x in miss]\n",
    "        # Error\n",
    "        err_m = np.dot(w,miss) / sum(w)\n",
    "        # Alpha\n",
    "        alpha_m = 0.5 * np.log( (1 - err_m) / float(err_m))\n",
    "        # New weights\n",
    "        w = np.multiply(w, np.exp([float(x) * alpha_m for x in miss2]))\n",
    "        # Add to prediction\n",
    "        pred_train = [sum(x) for x in zip(pred_train, \n",
    "                                          [x * alpha_m for x in pred_train_i])]\n",
    "        pred_test = [sum(x) for x in zip(pred_test, \n",
    "                                         [x * alpha_m for x in pred_test_i])]\n",
    "    \n",
    "    pred_train, pred_test = np.sign(pred_train), np.sign(pred_test)\n",
    "    \n",
    "    return pred_test\n",
    "    # Return error rate in train and test set\n",
    "#     return get_error_rate(pred_train, y_train), \\\n",
    "#            get_error_rate(pred_test, y_test)\n",
    "\n",
    "#Plot Function\n",
    "def plot_error_rate(er_train, er_test):\n",
    "    df_error = pd.DataFrame([er_train, er_test]).T\n",
    "    df_error.columns = ['Training', 'Test']\n",
    "    plot1 = df_error.plot(linewidth = 3, figsize = (8,6),\n",
    "            color = ['lightblue', 'darkblue'], grid = True)\n",
    "    plot1.set_xlabel('Number of iterations', fontsize = 12)\n",
    "    plot1.set_xticklabels(range(0,450,50))\n",
    "    plot1.set_ylabel('Error rate', fontsize = 12)\n",
    "    plot1.set_title('Error rate vs number of iterations', fontsize = 16)\n",
    "    plt.axhline(y=er_test[0], linewidth=1, color = 'red', ls = 'dashed')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Fit a simple decision tree first\n",
    "    clf_tree = DecisionTreeClassifier(max_depth = 5, random_state = 42)\n",
    "    er_tree = generic_clf(y_train, X_train, y_test, X_test, clf_tree)\n",
    "    \n",
    "    # Fit Adaboost classifier using a decision tree as base estimator\n",
    "    # Test with different number of iterations\n",
    "    er_train, er_test = [er_tree[0]], [er_tree[1]]\n",
    "    x_range = range(10, 200, 10)\n",
    "    y_pred = adaboost_clf(y_train, X_train, y_val, X_val, 0, clf_tree)\n",
    "    \n",
    "    print(accuracy_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Using this ensemble, carry out classification on the test set and report accuracy [1 mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration # 1\n",
      "iteration # 2\n",
      "iteration # 3\n",
      "iteration # 4\n",
      "iteration # 5\n",
      "iteration # 6\n",
      "iteration # 7\n",
      "iteration # 8\n",
      "iteration # 9\n",
      "iteration # 10\n",
      "iteration # 11\n",
      "iteration # 12\n",
      "iteration # 13\n",
      "iteration # 14\n",
      "iteration # 15\n",
      "iteration # 16\n",
      "iteration # 17\n",
      "iteration # 18\n",
      "iteration # 19\n",
      "iteration # 20\n",
      "0.14523809523809525\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    # Fit a simple decision tree first\n",
    "    clf_tree = DecisionTreeClassifier(max_depth = 5, random_state = 42)\n",
    "    er_tree = generic_clf(y_train, X_train, y_test, X_test, clf_tree)\n",
    "    \n",
    "    \n",
    "    # Fit Adaboost classifier using a decision tree as base estimator\n",
    "    # Test with different number of iterations\n",
    "    er_train, er_test = [er_tree[0]], [er_tree[1]]\n",
    "    x_range = range(10, 200, 10)\n",
    "    er_i = adaboost_clf(y_train, X_train, y_test, X_test, 0, clf_tree)\n",
    "    print(accuracy_score(y_test,er_i))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
